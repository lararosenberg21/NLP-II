{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c294fe57-c23f-4e78-af6d-5612a189a6fc",
   "metadata": {},
   "source": [
    "## TRABAJO PRACTICO 2: CHAT PARA CONSULTAR EL CV\n",
    "ALUMNA: Lara Rosenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5639934e-1def-4601-8a3c-49d763416c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\damia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\damia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos las librerias necesarias\n",
    "import os\n",
    "import streamlit as st\n",
    "from pinecone import Pinecone\n",
    "from groq import Groq\n",
    "from typing import List\n",
    "import nltk\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d53de-626b-407b-aafd-fe38257decd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las API KEY necesarias (Pinecone y Groq)\n",
    "os.environ['PINECONE_API_KEY'] = ''\n",
    "os.environ['GROQ_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8308d12-75f1-46db-8cd8-dbb3a33992e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para particionar el texto\n",
    "def read_and_chunk_sentences(\n",
    "    file_path: str,\n",
    "    chunk_size: int = 40,\n",
    "    overlap: int = 10\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Lee el archivo de texto, lo separa en oraciones y hace el chunk con overlap.\n",
    "\n",
    "    Argumentos:\n",
    "        file_path (str): Path al archivo de texto.\n",
    "        chunk_size (int): Numero de oraciones por chunk.\n",
    "        overlap (int): Numero de oraciones que estan en overlap.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Lista de chunks.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"{file_path} does not exist.\")\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text, language='spanish')\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        chunk = sentences[i:i+chunk_size]\n",
    "        if chunk:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "        i += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddaac53-8b31-4a5d-a864-bf5bd66a5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos las API KEY necesarias\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f41979-82c2-46fd-9b7f-f581d4a54944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\damia\\Anaconda3\\envs\\nuevo_entorno\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos cliente Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Definimos el nombre del índice\n",
    "index_name = \"cvlrf-index\"\n",
    "\n",
    "# Verificamos si ya existe, si no lo creamos\n",
    "if not pc.list_indexes() or index_name not in [i.name for i in pc.list_indexes()]:\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\": \"llama-text-embed-v2\",\n",
    "            \"field_map\": {\"text\": \"chunk_text\"}\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Nos conectamos a ese indice\n",
    "index_pc = pc.Index(index_name)\n",
    "\n",
    "# Leemos el archivo y lo dividimos en chunks\n",
    "chunks = read_and_chunk_sentences(\"CV LARA ROSENBERG.txt\", chunk_size=5, overlap=2)\n",
    "\n",
    "# Armamos los documentos en el formato requerido\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    documents.append({\n",
    "        \"_id\": f\"cv_chunk_{i + 1}\",\n",
    "        \"chunk_text\": chunk,\n",
    "        \"category\": \"cv\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e323fa72-9dd7-418a-8c69-4b59c3b5098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"cvlrf-index\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"cvlrf-index-b8qunng.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 1024,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null,\n",
       "    \"embed\": {\n",
       "        \"model\": \"llama-text-embed-v2\",\n",
       "        \"field_map\": {\n",
       "            \"text\": \"chunk_text\"\n",
       "        },\n",
       "        \"dimension\": 1024,\n",
       "        \"metric\": \"cosine\",\n",
       "        \"write_parameters\": {\n",
       "            \"dimension\": 1024.0,\n",
       "            \"input_type\": \"passage\",\n",
       "            \"truncate\": \"END\"\n",
       "        },\n",
       "        \"read_parameters\": {\n",
       "            \"dimension\": 1024.0,\n",
       "            \"input_type\": \"query\",\n",
       "            \"truncate\": \"END\"\n",
       "        },\n",
       "        \"vector_type\": \"dense\"\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validamos que la metrica por default sea coseno\n",
    "pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a123c1ca-aee7-4f0f-83ba-c131dac6db66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'cv_chunk_1',\n",
       "  'chunk_text': 'DATOS PERSONALES\\nLara Rosenberg \\nBuenos Aires, Argentina \\nEmail: lararosenberg21@gmail.com \\nTeléfono: +5491133948355 \\nFecha de Nacimiento: 7/10/1995\\n\\nRESUMEN PROFESIONAL:\\nEspecialista en ciencia de datos y modelado de riesgo crediticio con más de 6 años de experiencia en la industria financiera y tecnológica. Trayectoria consolidada en el desarrollo e implementación de modelos predictivos, machine learning y análisis de grandes volúmenes de datos. Fuerte formación técnica, con enfoque en soluciones de negocio basadas en datos y métricas de performance. EXPERIENCIA PROFESIONAL:\\n\\nMERCADO LIBRE (Marzo 2023 - Actualidad)\\n\\nCredit Risk Modeling Supervisor (Marzo 2024 - Actualidad)  \\n- Supervisión de estrategias de modelado de riesgo crediticio para productos financieros de la región. - Coordinación de equipo técnico y evaluación de performance de modelos.',\n",
       "  'category': 'cv'},\n",
       " {'_id': 'cv_chunk_2',\n",
       "  'chunk_text': 'EXPERIENCIA PROFESIONAL:\\n\\nMERCADO LIBRE (Marzo 2023 - Actualidad)\\n\\nCredit Risk Modeling Supervisor (Marzo 2024 - Actualidad)  \\n- Supervisión de estrategias de modelado de riesgo crediticio para productos financieros de la región. - Coordinación de equipo técnico y evaluación de performance de modelos. Credit Risk Modeling Sr Analyst (Marzo 2023 - Marzo 2024)  \\n- Desarrollo de modelos de score de riesgo utilizando técnicas de machine learning. - Análisis de performance crediticia y diseño de estrategias de originación. ALGORITHIA (Noviembre 2021 - Marzo 2023) \\nData Scientist   \\n- Implementación de modelos predictivos para clientes del sector financiero.',\n",
       "  'category': 'cv'},\n",
       " {'_id': 'cv_chunk_3',\n",
       "  'chunk_text': '- Análisis de performance crediticia y diseño de estrategias de originación. ALGORITHIA (Noviembre 2021 - Marzo 2023) \\nData Scientist   \\n- Implementación de modelos predictivos para clientes del sector financiero. - Desarrollo de pipelines de datos y soluciones en la nube. CÍRCULO DE CRÉDITO (Marzo 2020 - Noviembre 2021)\\nConsultor de Modelos  \\n- Construcción y monitoreo de modelos de riesgo de crédito y score de comportamiento. - Trabajo conjunto con áreas de negocio para la implementación de modelos.',\n",
       "  'category': 'cv'},\n",
       " {'_id': 'cv_chunk_4',\n",
       "  'chunk_text': 'CÍRCULO DE CRÉDITO (Marzo 2020 - Noviembre 2021)\\nConsultor de Modelos  \\n- Construcción y monitoreo de modelos de riesgo de crédito y score de comportamiento. - Trabajo conjunto con áreas de negocio para la implementación de modelos. BANCO PATAGONIA  (Septiembre 2019 - Marzo 2020)\\nAnalista de Riesgos Financieros    \\n- Evaluación del riesgo de mercado. - Automatización de reportes regulatorios. INSTITUTO ARGENTINO DE MERCADO DE CAPITALES (Agosto 2018 - Agosto 2019)\\nAnalista Financiero   \\n- Análisis de mercado de capitales y generación de reportes económicos.',\n",
       "  'category': 'cv'},\n",
       " {'_id': 'cv_chunk_5',\n",
       "  'chunk_text': '- Automatización de reportes regulatorios. INSTITUTO ARGENTINO DE MERCADO DE CAPITALES (Agosto 2018 - Agosto 2019)\\nAnalista Financiero   \\n- Análisis de mercado de capitales y generación de reportes económicos. METLIFE SEGUROS (Abril 2018 - Agosto 2018)\\nPasante \\n- Soporte al área de Global Actuarial Modeling. EDUCACIÓN:\\nPosgrado en Inteligencia Artificial  \\nUniversidad de Buenos Aires  \\n2024 - Actualidad  \\n\\nActuario en Economía  \\nUniversidad de Buenos Aires  \\n2014 - 2019  \\n\\n\\nCURSOS Y CERTIFICACIONES:\\n- Python Data Analytics (EANT)\\n- Data Science (Digital House)  \\n- Machine Learning with PySpark (Datacamp)  \\n- Big Data Fundamentals with PySpark (Datacamp)  \\n- Feature Engineering with PySpark (Datacamp)  \\n- Introduction to Relational Databases in SQL (Datacamp)  \\n- Joining Data in SQL (Datacamp)  \\n- SAS Programming I  \\n- SAS Enterprise Guide I  \\n\\n\\nCONOCIMIENTOS TÉCNICOS:\\nLenguajes: Python, SQL, SAS    \\nModelado: Machine Learning, Feature Engineering, Scorecards  \\nBases de datos: SQL relacional  \\n\\n\\nIDIOMAS:\\nEspañol: Nativo  \\nInglés: Avanzado',\n",
       "  'category': 'cv'},\n",
       " {'_id': 'cv_chunk_6',\n",
       "  'chunk_text': 'EDUCACIÓN:\\nPosgrado en Inteligencia Artificial  \\nUniversidad de Buenos Aires  \\n2024 - Actualidad  \\n\\nActuario en Economía  \\nUniversidad de Buenos Aires  \\n2014 - 2019  \\n\\n\\nCURSOS Y CERTIFICACIONES:\\n- Python Data Analytics (EANT)\\n- Data Science (Digital House)  \\n- Machine Learning with PySpark (Datacamp)  \\n- Big Data Fundamentals with PySpark (Datacamp)  \\n- Feature Engineering with PySpark (Datacamp)  \\n- Introduction to Relational Databases in SQL (Datacamp)  \\n- Joining Data in SQL (Datacamp)  \\n- SAS Programming I  \\n- SAS Enterprise Guide I  \\n\\n\\nCONOCIMIENTOS TÉCNICOS:\\nLenguajes: Python, SQL, SAS    \\nModelado: Machine Learning, Feature Engineering, Scorecards  \\nBases de datos: SQL relacional  \\n\\n\\nIDIOMAS:\\nEspañol: Nativo  \\nInglés: Avanzado',\n",
       "  'category': 'cv'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analizamos los documentos que se crearon\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d525d7b-25c2-49ed-9269-12bb1cb48931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace donde se guardarán los vectores\n",
    "namespace = \"cvlrf-namespace\"\n",
    "\n",
    "# Subimos los chunks al índice --> lo dejamos comentado porque ya lo hicimos la primera vez que corrimos esto.\n",
    "#index_pc.upsert_records(namespace=namespace, records=documents)\n",
    "#print(f\"Subidos {len(documents)} chunks al índice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50c48667-4dcf-4880-9c73-4ab04fbb65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar(text, top_k=10, namespace=\"cvlrf-namespace\", debug = False):\n",
    "    \"\"\"\n",
    "    Función para buscar los chunks de texto más similares a una consulta utilizando el indice.\n",
    "\n",
    "    Argumentos:\n",
    "    - text (str): La consulta o pregunta del usuario.\n",
    "    - top_k (int, opcional): Número de resultados más relevantes que se deben devolver. Por defecto es 10.\n",
    "    - namespace (str, opcional): El espacio de nombres donde se guardan los vectores. Por defecto es \"cvlrf-namespace\".\n",
    "    - debug (bool, opcional): Si se debe imprimir información de depuración sobre los resultados. Por defecto es False.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: Una lista de los chunks de texto más relevantes (en formato string) basados en la consulta.\n",
    "    \"\"\"\n",
    "    # Search the dense index\n",
    "    results = index_pc.search(\n",
    "        namespace=namespace,\n",
    "        query={\n",
    "            \"top_k\": top_k,\n",
    "            \"inputs\": {\n",
    "                'text': text\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print the results\n",
    "    data = []\n",
    "    for hit in results['result']['hits']:\n",
    "        tmp = f\"id: {hit['_id']:<5} | score: {round(hit['_score'], 2):<5} | category: {hit['fields']['category']:<10} | text: {hit['fields']['chunk_text']:<50}\"\n",
    "        if debug:\n",
    "            print(tmp)\n",
    "        data.append(tmp)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0b7c0d-721b-42f5-b88e-e3a1c84eab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(self, client, model=\"meta-llama/llama-4-scout-17b-16e-instruct\"):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "\n",
    "    def add_user_message(self, content):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "    def add_assistant_message(self, content):\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "    def chat(self, msg, temperature=1, max_completion_tokens=1024, top_p=1, stream=True, stop=None):\n",
    "        context_text = \"\"\n",
    "        context = search_similar(msg, top_k=10, debug=False)\n",
    "        context_text = \"\\n\\n\".join(context)\n",
    "        prompt = f\"\"\"\n",
    "Sos un asistente conversacional. Respondé de forma natural y conversacional.\n",
    "\n",
    "Sin embargo, si la pregunta se refiere a Lara Rosenberg o su currículum vitae, usá exclusivamente la información del siguiente contexto para responder. Si no encontrás la respuesta en el contexto, decilo claramente. Si la pregunta no tiene que ver con Lara, respondé normalmente sin usar el contexto.\n",
    "Consulta previa (historial): {self.messages}\n",
    "\n",
    "Consulta: {msg}\n",
    "\n",
    "Contexto:\n",
    "{context_text}\n",
    "\"\"\"\n",
    "        self.add_user_message(prompt.strip())\n",
    "\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=temperature,\n",
    "            max_completion_tokens=max_completion_tokens,\n",
    "            top_p=top_p,\n",
    "            stream=stream,\n",
    "            stop=stop\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        for chunk in completion:\n",
    "            delta = chunk.choices[0].delta.content or \"\"\n",
    "            response += delta\n",
    "        self.add_assistant_message(response)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97bb01-a90a-46d4-bfbd-6aae0b9f6c80",
   "metadata": {},
   "source": [
    "Testeamos el funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e03f4f5-c6f4-48be-8a1c-4329ca90c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si estamos en 2025 y Lara Rosenberg nació el 7 de octubre de 1995, eso significa que en 2025 tendría 30 años.\n"
     ]
    }
   ],
   "source": [
    "# 1. Hacemos una consulta\n",
    "query = \"¿Si estamos en 2025, cuantos anos tiene Lara?\"\n",
    "\n",
    "# 2. Creamos sesión de chat\n",
    "chat = ChatSession(client)\n",
    "\n",
    "# 3. Obtenemos respuesta generada\n",
    "respuesta = chat.chat(query)\n",
    "print(respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "920b252a-412b-4783-b9e9-242d04f9b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Según el contexto, Lara estudió Actuario en Economía en la Universidad de Buenos Aires desde 2014 hasta 2019. Por lo tanto, en 2015, Lara estaba estudiando Actuario en Economía.\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Que estudiaba Lara en 2015?\"\n",
    "respuesta = chat.chat(query)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eceb195-71d5-482d-844a-6e7d69f1d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Según el contexto, el último trabajo mencionado de Lara Rosenberg es como Credit Risk Modeling Supervisor en Mercado Libre desde marzo 2024 hasta la actualidad.\n"
     ]
    }
   ],
   "source": [
    "query = \"¿Cual fue el ultimo trabajo de Lara?\"\n",
    "respuesta = chat.chat(query)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199c05c4-53c3-44e0-98b5-d35f33b02707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Según el contexto, Lara Rosenberg ha trabajado en varias empresas:\n",
      "\n",
      "1. Mercado Libre (Marzo2023 - Actualidad)\n",
      "2. ALGORITHIA (Noviembre2021 - Marzo2023)\n",
      "3. CÍRCULO DE CRÉDITO (Marzo2020 - Noviembre2021)\n",
      "4. BANCO PATAGONIA (Septiembre2019 - Marzo2020)\n",
      "5. INSTITUTO ARGENTINO DE MERCADO DE CAPITALES (Agosto2018 - Agosto2019)\n",
      "6. METLIFE SEGUROS (Abril2018 - Agosto2018)\n",
      "\n",
      "Por lo tanto, Lara ha trabajado en 6 empresas diferentes.\n"
     ]
    }
   ],
   "source": [
    "query = \"¿En cuantas empresas trabajo Lara?\"\n",
    "respuesta = chat.chat(query)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02877f8-34db-4783-9120-b97f0885c07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nuevo_entorno)",
   "language": "python",
   "name": "nuevo_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
